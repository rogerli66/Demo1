172.27.37.54 zookeeper-1
172.27.37.56 zookeeper-2
172.27.37.57 zookeeper-3

- zookeeper-1:9092
- zookeeper-2:9092
- zookeeper-3:9092

su - kafka
kafka
zkServer.sh start conf/zoo.cfg

kafka-server-start.sh -daemon config/server.properties
kafka-topics.sh --create --zookeeper zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181  --replication-factor 1 --partitions 1 --topic demo-test

kafka-console-consumer.sh --zookeeper zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181 --topic sample_test --from-beginning

kafka-console-producer.sh --broker-list  zookeeper-1:9092,zookeeper-2:9092,zookeeper-3:9092 --topic sample_test

zkCli.sh -server  zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
zkCli.sh
  ls /brokers/ids
  ls /brokers/topics

HA second demo
1. setup local server for mdm
  a. run docker-compose ps -a
      docker volume prune
      docker-compose down
      cd C:\git-repo\mdm\docker-stack\basic
      docker-compose up -d
      docker-compose logs sqlserver
      docker-compose ps

      Open project of mdm in IntelliJ,
      Go BDD, click "run" trigle button
      then go bdd\src\main\groovy\com\tcf\mdm\test\mapping\RCIF\PersonAllFields.groovy, Click "Run It" on lef panel

      monitor plan for alerts from brokers get down.

      docker-compose exec kafka kafka-topics --create --zookeeper 172.27.37.54:2181 --replication-factor 1 --partitions 1 --topic registry-info-two
      kafka-topics.sh --list --zookeeper zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      kafka-topics.sh --describe --zookeeper zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      kafka-topics.sh --delete --zookeeper zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181 --topic __consumer_offsets,

      kafka-console-producer.sh --broker-list zookeeper-1:9092,zookeeper-2:9092,zookeeper-3:9092 --topic demo-test
      kafka-console-consumer.sh --bootstrap-server zookeeper-1:9092,zookeeper-2:9092,zookeeper-3:9092 --from-beginning --topic demo-test

  b. at c:\git-repo\ run git clone git@git.tcfbank.com:TCFBank/mdm.git
  c. Load MDM project into IntelliJ as a Gradle project from c:\git-repo\mdm
  d. Build "mdm" project by clicking 'Build Module "mdm"' on right clicking gradlew file
2  Run MDM Aggregators

    i.  Run /aggregator/rcif/src/main/java/com.tcf.mdm.aggregator.rcif/RcifAggregatorApplication.java
    ii. Run /aggregator/shaw/src/main/java/com.tcf.mdm.aggregator.shaw/ShawAggregatorApplication.java
    iii.  Get sample RCIF data files (from where?) and extract them into c:/temp
    iV.  Run RFFL13 load:
      POST=http://localhost:8081/api/rcif/rffl13
      {
          "filePath": "C:\\temp\\8_25_data\\TCFCIFTO.BD.CIF575.RFFL13.NAMES"
      }
    v. Verify tables created and populated in AGG_RCIF
3. Run MDM Processor

  i. Run /processor/src/main/java/com.tcf.mdm.processor/ProcessorApplication.java
  ii. Run Aggregation:
      POST=http://localhost:8081/api/rcif/aggregate
      {}
  ii. Verify tables created and populated in PROCESSOR

4. Build and run UI

  i. Open command window in
  ii. Run the command .\gradlew.bat clean build -b ui\build.gradle (some errors are expected but successful as long as 'Build complete.')
  iii. You should see some additional files under /ui/src/main/resources/static/static (css, fonts, img, js)
  iv. Run /search-service/src/main/java/com.tcf.mdm.search/SearchServiceApplication.java
  v. Open web browser and go to URL http://localhost:8084/

8/22/2018
MariaDB roll out to prod. in 35 sprint of release 1.3
tickets opened: RITM0118403, INC0345024

Spike Item B-23593 MariaDB firewall connection on inforSec requirements
DataDB connections db  (Dev & Rel: 2F@st4Y0u)
Create service accounts

Configure the Prod MariaDB server environment such that it is appropriate for storing production MDM data.
Â 

quay.io/tcfbank/mdm-validation-service:feature-1

kafka-consumer-groups.sh --bootstrap-server localhost:9092 --command-config config --describe --group target-service
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --command-config /tmp/config --describe --group target-service

ven to allow fail-over.
bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:2181 --list
